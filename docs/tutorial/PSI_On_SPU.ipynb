{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "eb4f5fec-1a5c-4b6f-b583-fb369472e94b",
      "metadata": {},
      "source": [
        "# PSI On SPU"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "4172c7c4",
      "metadata": {},
      "source": [
        ">The following codes are demos only. It's **NOT for production** due to system security concerns, please **DO NOT** use it directly in production."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "f9b632d8-b12f-44a1-8a75-5d9c0a704a38",
      "metadata": {},
      "source": [
        "PSI([Private Set Intersection](https://en.wikipedia.org/wiki/Private_set_intersection)) is a cryptographic technique that allows two parties holding sets to compare encrypted versions of these sets in order to compute the intersection. In this scenario, neither party reveals anything to the counterparty except for the elements in the intersection.\n",
        "\n",
        "In SecretFlow, SPU device supports three PSI protocol:\n",
        "\n",
        "- [ECDH](https://ieeexplore.ieee.org/document/6234849/)：semi-honest, based on public key encryption, suitable for small datasets.\n",
        "- [KKRT](https://eprint.iacr.org/2016/799.pdf)：semi-host, based on cuckoo hashing and OT extension, suitable for large datasets.\n",
        "- [BC22PCG](https://eprint.iacr.org/2022/334): semi-host, psi from pseudorandom correlation generators.\n",
        "\n",
        "Before we start, we need to initialize the environment. The following three nodes `alice`, `bob`, and `carol` are created on a single machine to simulate multiple participants."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d7c4fa2-ea20-4e0d-b1ad-648cce23e729",
      "metadata": {},
      "outputs": [],
      "source": [
        "import secretflow as sf\n",
        "\n",
        "# Check the version of your SecretFlow\n",
        "print('The version of SecretFlow: {}'.format(sf.__version__))\n",
        "\n",
        "# In case you have a running secretflow runtime already.\n",
        "sf.shutdown()\n",
        "\n",
        "sf.init(['alice', 'bob', 'carol'], address='local')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "00a798bd",
      "metadata": {},
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "5ed0a08b-3aa4-4fa6-9e1d-0caba207bdf5",
      "metadata": {},
      "source": [
        "## Preparing dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b4c16f07-1c67-4bad-af70-d8a4fe9266f3",
      "metadata": {},
      "source": [
        "First, we need a dataset for constructing vertical partitioned scenarios. For simplicity, we use [iris](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html) dataset here. We add two columns to it for subsequent single-column and multi-column intersection demonstrations\n",
        "\n",
        "- uid：Sample unique ID.\n",
        "- month：Simulate a scenario where samples are generated monthly. The first 50% of the samples are generated in January, and the last 50% of the samples are generated in February."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31f0a010-0a2e-4ee2-996a-169d7cb2731d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "data, target = load_iris(return_X_y=True, as_frame=True)\n",
        "data['uid'] = np.arange(len(data)).astype('str')\n",
        "data['month'] = ['Jan'] * 75 + ['Feb'] * 75\n",
        "\n",
        "data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "1bb263ff-e8a3-4066-ab30-ea01030a9f18",
      "metadata": {},
      "source": [
        "In the actual scenario, the sample data is provided by each participant, and the fields for intersection need to be agreed in advance:\n",
        "\n",
        "- The intersection field can be single or multiple.\n",
        "- The intersection field must be unique. If there is a duplicate, it needs to be deduplicated in advance.\n",
        "\n",
        "For example, The following is the data provided by alice for PSI intersection, the intersection field is `uid` and `month`，we can see that [1, 'Jan'] is duplicated.\n",
        "```\n",
        "alice.csv\n",
        "---------\n",
        "uid   month   c0\n",
        "1     Jan     5.8\n",
        "2     Jan     5.4\n",
        "1     Jan     5.8\n",
        "1     Feb     7.4\n",
        "```\n",
        "The data after deduplication is\n",
        "```\n",
        "alice.csv\n",
        "---------\n",
        "uid   month   c0\n",
        "1     Jan     5.8\n",
        "2     Jan     5.4\n",
        "1     Feb     7.4\n",
        "```\n",
        "We randomly sample the iris data three times to simulate the data provided by `alice`, `bob`, and `carol`, and the three data are in an unaligned state.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "037542dd-7945-4665-9d6a-7d805ea52b20",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.makedirs('.data', exist_ok=True)\n",
        "da, db, dc = data.sample(frac=0.9), data.sample(frac=0.8), data.sample(frac=0.7)\n",
        "\n",
        "da.to_csv('.data/alice.csv', index=False)\n",
        "db.to_csv('.data/bob.csv', index=False)\n",
        "dc.to_csv('.data/carol.csv', index=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "d54451db-c9ba-45ca-877b-06619e03215f",
      "metadata": {},
      "source": [
        "## Two parties PSI"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "7c12512f-4889-4f71-a539-e5bb7f56a9a5",
      "metadata": {},
      "source": [
        "We virtualize three logical devices on the physical device:\n",
        "\n",
        "- alice, bob: PYU device, responsible for the local plaintext computation of the participant.\n",
        "- spu：SPUdevice, consists of alice and bob, responsible for the ciphertext calculation of the two parties."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff729adb-f89a-499d-999f-6d884f2203e0",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "alice, bob = sf.PYU('alice'), sf.PYU('bob')\n",
        "spu = sf.SPU(sf.utils.testing.cluster_def(['alice', 'bob']))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "fb2b161a-5aa9-4d06-b866-48b25273e48b",
      "metadata": {},
      "source": [
        "### Single-column PSI"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c12444e3-1da0-426e-add2-609770f8f259",
      "metadata": {},
      "source": [
        "Next, we use `uid` to intersect the two data, SPU provide `psi` which take the csv file as input and generate the csv file after the intersection. The default protocol is KKRT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dec15656-51c1-4498-9f78-b2bcfd5168fb",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "input_path = {alice.party: '.data/alice.csv', bob.party: '.data/bob.csv'}\n",
        "output_path = {alice.party: '.data/alice_psi.csv', bob.party: '.data/bob_psi.csv'}\n",
        "spu.psi({alice.party:[\"uid\"], bob.party: [\"uid\"]}, input_path, output_path, 'alice', disable_alignment=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "1ef80302-548f-4277-a460-fee0a07b7728",
      "metadata": {},
      "source": [
        "To check the correctness of the results, we use [pandas.DataFrame.join](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html) to inner join da and db. It can be seen that the two data have been aligned according to `uid` and sorted according to their lexicographical order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec091c3a-83bc-41f4-85d5-351c9d98c643",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df:pd.DataFrame = da.join(db.set_index('uid'), on='uid', how='inner', rsuffix='_bob', sort=True)\n",
        "expected = df[da.columns].astype({'uid': 'int64'}).sort_values(by='uid', ascending=True).reset_index(drop=True)\n",
        "\n",
        "da_psi = pd.read_csv('.data/alice_psi.csv').sort_values(by='uid', ascending=True).reset_index(drop=True)\n",
        "db_psi = pd.read_csv('.data/bob_psi.csv').sort_values(by='uid', ascending=True).reset_index(drop=True)\n",
        "\n",
        "pd.testing.assert_frame_equal(da_psi, expected)\n",
        "pd.testing.assert_frame_equal(db_psi, expected)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "4e1015b1-4062-4f40-8c5b-3b3e346cd4d2",
      "metadata": {},
      "source": [
        "### Multi-columns PSI"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "26bdf77c-dd58-4053-a3f4-f69659c8c96e",
      "metadata": {},
      "source": [
        "We can also use multiple fields to intersect, the following demonstrates the use of `uid` and `month` to intersect two data. In terms of implementation, multiple fields are concatenated into a string, so please ensure that there is no duplication of the multi-column composite primary key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db24b582-ef58-4791-89d5-074be619d23f",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "spu.psi({alice.party:['uid', 'month'], bob.party:['uid', 'month']}, input_path, output_path, 'alice')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "f7b34956-48c7-4e0f-bb6a-013508866267",
      "metadata": {},
      "source": [
        "Similarly, we use pandas.DataFrame.join to verify the correctness of the result, we can see that the two data have been aligned according to `uid` and `month`, and sorted according to their lexicographical order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aebb3a76-977b-4856-b17d-066fd43230c8",
      "metadata": {},
      "outputs": [],
      "source": [
        "df:pd.DataFrame = da.join(\n",
        "    db.set_index(['uid', 'month']),\n",
        "    on=['uid', 'month'],\n",
        "    how='inner',\n",
        "    rsuffix='_bob',\n",
        "    sort=True,\n",
        ")\n",
        "expected = df[da.columns].astype({'uid': 'int64'}).sort_values(by='uid', ascending=True).reset_index(drop=True)\n",
        "\n",
        "da_psi = pd.read_csv('.data/alice_psi.csv').sort_values(by='uid', ascending=True).reset_index(drop=True)\n",
        "db_psi = pd.read_csv('.data/bob_psi.csv').sort_values(by='uid', ascending=True).reset_index(drop=True)\n",
        "\n",
        "pd.testing.assert_frame_equal(da_psi, expected)\n",
        "pd.testing.assert_frame_equal(db_psi, expected)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "f87f2dc4-c6c8-409a-b83d-fa15661def83",
      "metadata": {},
      "source": [
        "## Three parties PSI"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "82d884a3-4c6b-47ac-8526-ff486e89bcd4",
      "metadata": {},
      "source": [
        "Next, we add a third-party `carol`, and create a PYU device for it, as well as an SPU device built by the third party."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7eb7050f-70e4-4dc6-9f07-b19b8aeb69bc",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "carol = sf.PYU('carol')\n",
        "spu_3pc = sf.SPU(sf.utils.testing.cluster_def(['alice', 'bob', 'carol']))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "eee3d13d-c648-4072-9ebd-c50787701262",
      "metadata": {},
      "source": [
        "Then, use `uid` and `month` as the composite primary key to perform a three-way negotiation. It should be noted that the three-way negotiation only supports the ECDH protocol for the time being."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91f58d96-ef7c-411d-9cc4-524ef1c0dd44",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "input_path = {alice.party: '.data/alice.csv', bob.party: '.data/bob.csv', carol.party: '.data/carol.csv'}\n",
        "output_path = {\n",
        "    alice.party: '.data/alice_psi.csv',\n",
        "    bob.party: '.data/bob_psi.csv',\n",
        "    carol.party: '.data/carol_psi.csv',\n",
        "}\n",
        "keys = ['uid', 'month']\n",
        "spu_3pc.psi(\n",
        "    {alice.party:keys, bob.party:keys, carol.party:keys}, input_path, output_path, 'alice', protocol='PROTOCOL_ECDH_3PC'\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "17461ac1-1409-45ef-a513-ecfe6482feb8",
      "metadata": {},
      "source": [
        "Similarly, we use pandas.DataFrame.join to verify the correctness of the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6ea04f0-6b8a-40d7-b07a-06e926884261",
      "metadata": {},
      "outputs": [],
      "source": [
        "keys = ['uid', 'month']\n",
        "df = da.join(db.set_index(keys), on=keys, how='inner', rsuffix='_bob', sort=True).join(\n",
        "    dc.set_index(keys), on=keys, how='inner', rsuffix='_carol', sort=True\n",
        ")\n",
        "expected = df[da.columns].astype({'uid': 'int64'}).reset_index(drop=True)\n",
        "\n",
        "da_psi = pd.read_csv('.data/alice_psi.csv')\n",
        "db_psi = pd.read_csv('.data/bob_psi.csv')\n",
        "dc_psi = pd.read_csv('.data/carol_psi.csv')\n",
        "\n",
        "pd.testing.assert_frame_equal(da_psi, expected)\n",
        "pd.testing.assert_frame_equal(db_psi, expected)\n",
        "pd.testing.assert_frame_equal(dc_psi, expected)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "6f4bb1ed-2530-46c4-b540-8c779dd93439",
      "metadata": {},
      "source": [
        "## What's Next"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "55afbe9a-2855-41d6-b867-ec61c4ba4d20",
      "metadata": {},
      "source": [
        "OK! Through this tutorial, we have seen how to do two-party and three-party data intersections via SPU. After completing the data intersection, we can perform machine learning modeling on the aligned dataset.\n",
        "\n",
        "- [Logistic Regression On SPU](./lr_with_spu.ipynb): Logistic regression modeling on SPU using JAX.\n",
        "- [Neural Network on SPU](./nn_with_spu.ipynb): Neural Network Modeling on SPU with JAX.\n",
        "- [Basic Split Learning](./split_learning_gnn.ipynb): Neural Network Modeling with TensorFlow and Split Learning."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "secretflow",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
